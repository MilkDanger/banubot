binary search complexity|O(log n)
merge sort complexity|O(n log n)
selection sort complexity|O(n^2)
insertion sort complexity|O(n^2)
insertion sort best case|O(n)
bubble sort complexity|O(n^2)
is merge sort stable?|yes
quick sort complexity|O(n log n)
quick sort worst case|O(n log n)
quick sort # of comparissons|n(n-1)
quick sort number of levels|n - 1
predicate|logical statement whose truth value is a function
proposition|has no free variables
Demorgan's Law: ~∀ x P(x) =|Ǝ x ~P(x)
~Ǝ x P(x) =| ∀ x ~P(x)
recurrence relation|a recursive definition of a sequence
a recursive definition of a set needs|basis: an elem in set, recursive rule: build elem from known elem
4 steps of proofs with loop invariants|1. Show if the preconditions is true, the loop invariant is true
2.|Show if the loop condition and invariant true before iteration, the invariant is true after iteration
3.|Show the condition will eventually be false
4.|Show if the condition is false and the loop invariant is true, then the post condition is true
a node is a max heap|true
sort a heap complexity|O(n)
bucket sort is a stable sort|true
bucket sort complexity|O(n + b) 
recursing into buckets complexity|O(n log n)
counting sort complexity|O(n + b)
counting sort is stable|true
formal definition θ|θ(g(n)) = {f(n) st Ǝ c1 > 0, c2 > 0, n0 > 0, ∀ n >= n0, (0 <= c1 g(n) <= f(n) <= c2 g(n))}
formal definition O|O(g(n)) = {f(n) st Ǝ c > 0, n0 > 0, ∀ n >= n0, (0 <= f(n) <= c g(n))}   
θ is asymptotically tight|true
O is asymptotically tight|false
Ω formal definition|{f(n) st Ǝ c > 0, n0 > 0, ∀ n >= n0, (0 <= c g(n) <= f(n))}
heap parent from child|(i - 1) / 2
heap child from parent|(i * 2) + 1 left i * 2 + 2 right
radix sort complexity|O(d n) d = number of digits
o formal definition| o(g(n)) = {f(n) : lim n -> inf f(n) / g(n)}
ω formal definition| {f(n) st Ǝ c > 0, n0 > 0, ∀ n >= n0, (0 <= c g(n) < f(n))} 
if f(n) = ω(g(n)) then|g(n) = o(f(n))
a polynomial function is always __ than a log function|larger 
recurrence is a recursive algorithm|false, it's a function
master method|T(n) = a T (n / b) + f(n)
a __ 1, b __ 1|a >= 1, b > 1
case 2 T(n) = |θ(n^(log b a) log n)
case 1 f(n) = |O(n^log b (a - e))
case 1 T(n) = |θ(n^(log b a))
case 3 f(n) = |Ω (n^log b (a + e))
case 3 T(n) = |θ(f(n))
